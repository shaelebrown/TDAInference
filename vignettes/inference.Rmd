---
title: "Statistical inference on persistence diagrams with TDAInference"
author: "Shael Brown"
output: 
  rmarkdown::html_vignette:
    fig_caption: yes
vignette: >
  %\VignetteIndexEntry{inference}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
references:
- id: Robinson_Turner
  title: 'Hypothesis testing for topological data analysis'
  author:
  - family: Robinson
    given: Andrew
  - family: Turner
    given: Katharine
  container-title: Journal of Applied and Computational Topology
  volume: 1
  URL: 'https://doi.org/10.1007/s41468-017-0008-7'
  DOI: 10.1007/s41468-017-0008-7
  page: 241
  type: article-journal
  issued:
    year: 2017
- id: distance_calc
  title: 'Geometry Helps to Compare Persistence Diagrams'
  author:
  - family: Kerber
    given: Michael
  - family: Morozov
    given: Dmitriy
  - family: Nigmetov
  given: Arnur
  container-title: ACM Journal of Experimental Algorithmics
  volume: 22
  URL: 'https://doi.org/10.1145/3064175'
  DOI: 10.1145/3064175
  page: 1
  type: article-journal
  issued:
    year: 2017
- id: dependencies
  title: 'Statistical Inference for Persistent Homology applied to fMRI'
  author:
  - family: Abdallah
    given: Hassan
  - family: Regalski
    given: Adam
  - family: Behzad Kang
    given: Mohammad
  - family: Berishaj
    given: Maria
  - family: Nnadi
    given: Nkechi
  - family: Chowdury
    given: Asadur
  - family: Diwadkar
    given: Vaibhav
  - family: Salch
    given: Andrew
  container-title: Github
  URL: 'https://github.com/hassan-abdallah/Statistical_Inference_PH_fMRI/blob/main/Abdallah_et_al_Statistical_Inference_PH_fMRI.pdf'
  type: article-journal
  issued:
    year: 2021
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Statistical inference of persistence diagrams

In this package functionality is provided to make statistical inference on groups of persistence diagrams. At a high level, we have groups of objects called persistence diagrams and wish to know if there is a difference between them. As detailed in @Robinson_Turner we compute an analogue to within group variance by calculating distances between each same-group pair of persistence diagrams, and then repeat this calculation many times for permuted group labels. The p-value for the test is computed as a smoothed ratio of the number of permutations which resulted in a within-group variance which was lower than the originally-calculated test statistic to the total number of permutations. Now, we'll provide more details as to how the computations are actually carried out.

One of the central objects of interest in topological data analysis (TDA) is called a persistence diagram. A persistence diagram for a point cloud data set is a topological descriptor which keeps track of various topological features of the data set. A persistence diagram is represented as a set of 2D points above the diagonal, for each topological dimension. We can compute distances between persistence diagrams in the same dimension by finding optimal matching of their 2D points, either using a $p$-Minkowski distance leading to the ''$p$-wasserstein distance'' or using the infinity-norm distance leading to the ''bottleneck distance'' @distance_calc. The inifinity-norm distance between two 2D points is just the maximum absolute distance between either coordinate: $d_{\infty} = \max\{|x_{1}-x_{2}|,|y_{1}-y_{2}|\}$. The $p$-Minkowski distance between two 2D points is either defined as $d_{p}((x_{1},y_{1}),(x_{2},y_{2})) = (|x_{1}-x_{2}|^p+|y_{1}-y_{2}|^p)^{1/p}$ in @Robinson_Turner, or $d_{p}((x_{1},y_{1}),(x_{2},y_{2})) = d_{\infty}((x_{1},y_{1}),(x_{2},y_{2}))^{1/p}$ in @distance_calc. The difference between these two definitions of the wasserstein distance are subtle but important -  the infinity-norm distance tends to find extreme distances whereas Minkowki distances are averaged over both coordinates and are often smaller. A matching of two persistence diagrams $D_{1},D_{2}$ in the same dimension $dim$ is $\phi:D_{1} \rightarrow D_{2}$ where each point $p_{1}$ in $D_{1}$ is "matched" to a point $\phi(p_{1})$ which is either a point in $D_{2}$ or is the projection (nearest point) of $p_{1}$ onto the diagonal, and every point in $D_{2}$ is matched to either a point in $D_{1}$ or to its projection on the diagonal. We can compute the optimal matching  by minimizing the loss function 

$$\sum_{p_{1},p_{2}}d(p_{1},\phi(p_{1}))$$ where $d$ is the desired metric (one of the two wasserstein definitions or the inifinity-norm distance). This optimization problem can be solved exactly by the Hungarian algorithm in the clue package.

Now that we have defined distances between persistence diagrams we can discuss how to make inferences about groups of persistence diagrams. For the basic idea we will consider two groups of persistence diagrams, $G_{1}$ and $G_{2}$, containing $n_{1}$ and $n_{2}$ persistence diagrams respectively. Each persistence diagram comes from a dataset, which could be viewed as a sample from a true "underlying" manifold (geometric object). Therefore, we might want to test if the groups $G_{1}$ and $G_{2}$ are samples of persistence diagrams coming from the same manifold, $H_{0}$, or if the underlying manifolds are different $H_{A}$. We start by computing a test-statistic, $L$, which is essentially the sum of within-group variances:

$$L = \frac{1}{n_{1}(n_{1}-1)}\sum_{D_{1} \neq D_{2} \in G_{1}}d(D_{1},D_{2})^{q} + \frac{1}{n_{2}(n_{2}-1)}\sum_{D_{1} \neq D_{2} \in G_{2}}d(D_{1},D_{2})^{q}$$

Here, $q$ is some finite exponent which is at least 1, and $d$ is the desired distance of persistence diagrams. $L$ is the test statistic for our hypothesis test.

Since relatively little is known about the distribution of persistence diagrams a permutation test procedure allows us to determine a suitable null distribution for making inferences. We will shuffle the group labels of the persistence diagrams (effectively moving them between the two groups) $N$ times and recompute the test statistic each time to obtain a list of "permutation values" $\{L_{1},\dots,L_{N}\}$. The idea is that if the groups are truly different, i.e. coming from different manifold objects, then there should be relatively small within group variances compared to when we shuffle the group labels. Therefore, let $NZ$ be the number of permutations $i$ such that $L_{i} < L$. Then the p-value of the test is $\frac{NZ+1}{N+1}$.

The extension to multiple groups, noted at the end of the paper @Robinson_Turner, is extremely straightforward and is implemented in this package. The null hypothesis is that all the groups are sampled from the same geometric object, and the alternative hypothesis is that some of the groups are sampled from different geometric objects. The test statistic is still the sum of the (essentially) within-group variances across all the groups, the permutations shuffle the persistence diagrams between all the groups, and the p-value is computed in the same way.

There is one additional functionality that this package provides, and it is an idea that was discussed in @dependencies. One of the assumptions of the inference procedure listed in @Robinson_Turner is that the persistence diagrams are all independent, however this is not always reasonable to assume in practice. For example, suppose we had point cloud data for several subjects in a pharmaceutical study both before and after a drug intervention. We might want to know if the geometric structure of the point clouds changed after the drug intervention, so our two groups of persistence diagrams would be the before intervention and after invention groups. Since there is a pairing between some of the persistence diagrams (the diagrams belonging to the same patient) these diagrams will not be independent of each other. From this perspective, we will only allow permutations which keep the two (or more in the case of many diagram groups) persistence diagrams of each patient (i.e. dependency) separated. So after each permutation each group still contains one persistence diagram per patient. Not only is this more ideal theoretically, but it also offers a practical advantage. If there was truly a difference between the groups then if there are subject differences the permuted-within-group variances would be larger when each group contains one persistence diagram from each subject, enhancing the test power.

To demonstrate the utility of the TDAInference package, we will go through several examples. Firstly, we will give some examples to show that the various distances between persistence diagrams are being computed correctly. Secondly, we will benchmark the distance calculations to show that they are faster than those provided in the TDA package. Thirdly, we will carry out various permutation tests with multiple groups either sampled from the same or different objects to show that the permutation test returns expected results.

```{r setup}
library("TDAInference")
```

## Case study: `first`

Let us construct a few examples of diagrams which we can easily calculate by hand what their distances should be. Let $D_1$ be the diagram with a single point $(2,3)$. Now, let $D_2 = \{(2,3.1),(5,6)\}$, $D_3 = \{(1,1.1),(3,3.1)\}$. We can visualize the three diagrams below:

```{r}
# D1
plot(x = 2,y = 3,xlab = "Birth",ylab = "Death",main = bquote("" ~ D[1]),xlim = c(0,6),ylim = c(0,6),pch = 16)
abline(a = 0,b = 1)

# D2
plot(x = c(2,5),y = c(3.1,6),xlab = "Birth",ylab = "Death",main = bquote("" ~ D[2]),xlim = c(0,6),ylim = c(0,6),pch = 16)
abline(a = 0,b = 1)

# D3
plot(x = c(1,3),y = c(1.1,3.1),xlab = "Birth",ylab = "Death",main = bquote("" ~ D[3]),xlim = c(0,6),ylim = c(0,6),pch = 16)
abline(a = 0,b = 1)

```

Now, for each pair of diagrams $(D_i,D_j)$ and each distance metric it's clear what the distance value should be. Note that for all metrics the matchings are the same in the different diagram pairings. In $d(D_1,D_2)$, $(2,3)$ is matched with $(2,3.1)$ and $(5,6)$ is matched with its diagonal projection, $(5.5,5.5)$. Therefore, using the 2-wasserstein metric the distance should be $\sqrt{0.1^2+0.5^2} \approx 0.1870829$, using the Turner metric with $p = 2$ the distance should be $\sqrt{d_{E}((2,3),(2,3.1))^2+d_{E}((5,6),(5.5,5.5))^2} \approx 0.7141428$, and using the Infinity norm distance the distance should be $0.1 + 0.5 = 0.6$. In each case the diagram_distance function returns the expected value:

```{r}
diagram_distance(D1 = data.frame(dimension = 0,birth = 2,death = 3),D2 = data.frame(dimension = 0,birth = c(2,5),death = c(3.1,6)),p = 2,distance = "wasserstein",dim = 0)

diagram_distance(D1 = data.frame(dimension = 0,birth = 2,death = 3),D2 = data.frame(dimension = 0,birth = c(2,5),death = c(3.1,6)),p = 2,distance = "Turner",dim = 0)

diagram_distance(D1 = data.frame(dimension = 0,birth = 2,death = 3),D2 = data.frame(dimension = 0,birth = c(2,5),death = c(3.1,6)),p = Inf,distance = "Turner",dim = 0)

```

We can do similar calculations for each of the other pairs $(D_1,D_3)$ and $(D_2,D_3)$. For $(D_1,D_3)$ the optimal matchine is each point with its diagonal projection: $(2,3)$ with $(2.5,2.5)$, $(1.1.1)$ with $(1.05,1.05)$ and $(3,3.1)$ with $(3.05,3.05)$. It is easy to verify that the distance should be $\sqrt{0.5} + 2*\sqrt{0.05} \approx 1.15432$ for the 2-wasserstein metric, $\frac{1}{\sqrt{2}} \approx 0.7071068$ for the $p = 2$ Turner metric, and $0.5+0.05+0.05 = 0.6$ for the Infinity norm metric. We see that those calculations were carried out correctly by the digram_distance function as well:

```{r}
diagram_distance(D1 = data.frame(dimension = 0,birth = 2,death = 3),D2 = data.frame(dimension = 0,birth = c(1,3),death = c(1.1,3.1)),p = 2,distance = "wasserstein",dim = 0)

diagram_distance(D1 = data.frame(dimension = 0,birth = 2,death = 3),D2 = data.frame(dimension = 0,birth = c(1,3),death = c(1.1,3.1)),p = 2,distance = "Turner",dim = 0)

diagram_distance(D1 = data.frame(dimension = 0,birth = 2,death = 3),D2 = data.frame(dimension = 0,birth = c(1,3),death = c(1.1,3.1)),p = Inf,distance = "Turner",dim = 0)

```

Finally, we will check the distances computed between $D_2$ and $D_3$. The optimal matching in all cases is given by $(2,3.1)$ and $(3,3.1)$, $(5,6)$ with its diagonal projection $(5.5,5.5)$, and $(1,1.1)$ with its diagonal projection $(1.05,1.05)$. The 2-wasserstein metric should be $1+$, the $p=2$ Turner metric should be $1+\frac{1}{\sqrt{2}} + \frac{1}{10\sqrt{2}} \approx 1.777817$, and the Infinity norm distance should be $1 + 0.5 + 0.05 = 1.55$.


```{r}
diagram_distance(D1 = data.frame(dimension = 0,birth = c(2,5),death = c(3.1,6)),D2 = data.frame(dimension = 0,birth = c(1,3),death = c(1.1,3.1)),p = 2,distance = "wasserstein",dim = 0)

diagram_distance(D1 = data.frame(dimension = 0,birth = c(2,5),death = c(3.1,6)),D2 = data.frame(dimension = 0,birth = c(1,3),death = c(1.1,3.1)),p = 2,distance = "Turner",dim = 0)

diagram_distance(D1 = data.frame(dimension = 0,birth = c(2,5),death = c(3.1,6)),D2 = data.frame(dimension = 0,birth = c(1,3),death = c(1.1,3.1)),p = Inf,distance = "Turner",dim = 0)

```

## Case study: benchmarking diagram_distance function

Now we will benchmark the runtime of the distance calculations on different-sized random persistence diagrams compared to calculations using the package TDA. 

## Case study: testing the permutation_test function

Now we will compare the permutation test results of multiple groups of persistence diagram drawn from the same distribution of points, and multiple groups of diagrams drawn from different shapes.

## References


