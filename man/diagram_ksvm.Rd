% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/machine_learning.R
\name{diagram_ksvm}
\alias{diagram_ksvm}
\title{Fit a support vector machine model to a regression task where the training set is a list of persistence diagrams}
\usage{
diagram_ksvm(
  diagrams,
  dim,
  t = 1,
  sigma = 1,
  y,
  type = NULL,
  C = 1,
  nu = 0.2,
  epsilon = 0.1,
  prob.model = F,
  class.weights = NULL,
  cross = 0,
  fit = T,
  cache = 40,
  tol = 0.001,
  shrinking = T,
  ...
)
}
\arguments{
\item{diagrams}{a list of persistence diagrams, as the output of a TDA calculation.}

\item{dim}{the homological dimension in which the distance is to be computed.}

\item{t}{the positive scale for the persistence Fisher kernel, default 1.}

\item{sigma}{a positive number representing the bandwith for the Fisher information metric, default 1}

\item{y}{a response vector with one label for each persistence diagram.}

\item{type}{type of task to be performed.}

\item{C}{cost of contraints violation (default 1) this is the 'C'-constant of the regularization term in the Lagrange formulation.}

\item{nu}{parameter needed for nu-svc, one-svc and nu-svr. The `nu` parameter sets the upper bound on the training error and the lower bound on the fraction of data points to become Support Vector (default 0.2).}

\item{epsilon}{epsilon in the insensitive-loss function used for eps-svr, nu-svr and eps-bsvm (default 0.1).}

\item{prob.model}{if set to TRUE builds a model for calculating class probabilities or in case of regression, calculates the scaling parameter of the Laplacian distribution fitted on the residuals. Fitting is done on output data created by performing a 3-fold cross-validation on the training data. For details see references (default FALSE).}

\item{class.weights}{a named vector of weights for the different classes, used for asymmetric class sizes. Not all factor levels have to be supplied (default weight: 1). All components have to be named.}

\item{cross}{if a integer value k>0 is specified, a k-fold cross validation on the training data is performed to assess the quality of the model: the accuracy rate for classification and the Mean Squared Error for regression.}

\item{fit}{indicates whether the fitted values should be computed and included in the model or not (default TRUE).}

\item{cache}{cache memory in MB (default 40).}

\item{tol}{tolerance of termination criteria (default 0.001).}

\item{shrinking}{option whether to use the shrinking-heuristics (default TRUE).}

\item{...}{additional parameters.}
}
\value{
a list containing the output of cmdscale on the diagram distance matrix, either just the embedding matrix or a list, the diagram groups, dimension, t, sigma and features. The class of this object is 'diagram_kpca'.
}
\description{
Returns the output of ksvm on the Gram matrix of a group of persistence diagrams
in a particular dimension.
}
\details{
The `diagrams` parameter should be a list of persistence diagrams computed from TDA.
The `dim` parameter should be a positive finite integer.
The `sigma` and `t` parameters are the positive bandwith for the Fisher information metric and
the positive scale for the persistence Fisher kernel respectively.
`type`, `C`, `nu`, `epsilon`, `prob.model`, `class.weights`, `cross`, `fit`, `cache`, `tol`, `shrinking` and
`...` are additional parameters to the ksvm kernlab function.
}
\examples{

# create ten diagrams with package TDA based on 2D Gaussians
g <- lapply(X = 1:10,FUN = function(X){

diag <- TDA::ripsDiag(data.frame(x = rnorm(100,mean = 0,sd = 1),
y = rnorm(100,mean = 0,sd = 1)),
maxscale = 1,
maxdimension = 1)
df <- diagram_to_df(d = diag)
return(df)

})

# create random response vector
y <- stats::runif(10,min = 0,max = 1)

# calculate model in dimension 1
model_svm <- diagram_ksvm(diagrams = g,dim = 1,y = y)
}
